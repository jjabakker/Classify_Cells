---
title: "Debug SVM"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include = FALSE} 
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
rm(list = ls())
set.seed(1234)
```


# Specify key use parameters

Model and datset options are:

"Baron_Mouse"
"Segerstolpe"
"Muraro"
"Xin"
"c_Muraro_Segerstolpe"
"c_Xin_Segerstolpe"
"Zhou"
"Bo"
"Petropoulos1"


```{r}

# Select dataset 

dataset_name         <- "Bo"

# Select preprocessing

preproc_method       <- "pp_no_pca"
preproc_method       <- "pp_log_pca"
preproc_method       <- "pp_pca"

# Specify which models should be run
# Note that it possible that a model is not available in the modelset, in which case the instruction is simply ignored

TRAIN_GBM_PP_PCA     <- TRUE
TRAIN_GBM_PP_NO_PCA  <- TRUE
TRAIN_GBM_PP_LOG     <- TRUE

```


# Initialise

```{r, libraries, message=FALSE}

library(readr)
library(tibble)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(Seurat)
library(caret)
library(data.table)
library(matrixStats)
library(tictoc)
library(MazamaCoreUtils)        # Used for logging messages to a file

source("Code/Train/seurat_analysis.R")
source("Code/Train/read_dataset.R")
source("Code/Predict/predict_model_with_labels.R")

```


```{r, initialise, message=FALSE}

PCA_Threshold    <- 0.90         # The percentage variance explained by the PCA
                                 # A high percentage requires more PC dimensions to be considered

features_limit   <- 1000         # The number of features that will be considered duringthe PCA
                                 # A high number uses the richness of the data set optimally, but makes processing slo

VERBOSE          <- TRUE         # If TRUE generates analysis data
SEURAT_VERBOSE   <- FALSE
VARIABLE_GENES   <- TRUE
LOGGER           <- FALSE

# Summary results will be kept here 
report_out       <- data.frame()

# Information of all the runs will be gathered in the class_summaries list  
class_summaries <- list()

```


```{r, preprocess options}

if (preproc_method == "pp_pca")  {
  log_preprocess   <- FALSE
  caret_preprocess_method <- c('scale', 'center', 'pca')
} else if (preproc_method == "pp_no_pca")  {
  log_preprocess   <- FALSE
  caret_preprocess_method <- c('scale', 'center')
} else if (preproc_method == "pp_log_pca")  {
  log_preprocess   <- TRUE
  caret_preprocess_method <- c('scale', 'center', 'pca')
}

```


```{r, path and timer}

proj_path   <- file.path(".")
data_path   <- file.path(proj_path, "DataSets")
log_path    <- file.path(proj_path, "Logs")
rdata_path  <- file.path(proj_path, "rData")
config_path <- file.path(proj_path, "config")

logger.setup (infoLog = file.path(log_path, paste0("pp_compare.log")))

```

# Read in the data


```{r, Read}


ret    <- read_dataset(data_path, dataset_name)
data   <- ret$data
labels <- ret$labels

if (log_preprocess) {
  data <- log(1 + data)
}

# Remove small classes
min_class_size      <- 10
removed_classes     <- !(table(labels$ident) > min_class_size)
cells_to_keep       <- !(is.element(labels[,1], names(removed_classes)[removed_classes]))
ori                 <- dim(data)[1] 
data                <- data[cells_to_keep,]
labels              <- labels[cells_to_keep,]
labels$ident        <- factor(labels$ident)
rm(removed_classes, cells_to_keep)

# Show composition
cat(sprintf("Information on dataset after removing small classes"))
cat(sprintf("Removed %d cells from small classes\n\n", ori - dim(data)[1] )) 

cat(sprintf("There are %d cells and %d features.\n", dim(data)[1], dim(data)[2]))
for (i in 1:length(table(labels$ident))) {
  cat(sprintf("%-25s %d\n", names(table(labels$ident)[i]), table(labels$ident)[i]))
}
cat(sprintf("\n"))

# Remove genes that are 0 for all cells
genes_to_keep <- (colSums(data) != 0)
cat(sprintf("\n"))
ori           <- dim(data)[2]
data          <- data[, genes_to_keep]

# Show composition
cat(sprintf("Information on processed dataset %s\n", dataset_name))
cat(sprintf("Removed %d all-zero genes\n\n",ori - dim(data)[2])) 
cat(sprintf("There are %d cells and %d features.\n\n", dim(data)[1], dim(data)[2]))
for (i in 1:length(table(labels$ident))) {
  cat(sprintf("%-25s %d\n", names(table(labels$ident)[i]), table(labels$ident)[i]))
}

```


# Find the Variable Genes 

```{r, variable_features, fig.height=5, message = FALSE, echo=FALSE}


seurat_object <- CreateSeuratObject(counts    = t(data),
                                    meta.data = as.data.frame(labels),
                                    min.cells = 5)

seurat_object <- NormalizeData(seurat_object, 
                               normalization.method = "LogNormalize", 
                               scale.factor = 1000000)

seurat_object <- FindVariableFeatures(object           = seurat_object, 
                                      selection.method = 'vst',
                                      verbose          = TRUE,
                                      nfeatures        = dim(data)[2])

# Identify the most highly variable genes
top_genes      <- VariableFeatures(seurat_object)

# Show composition
cat(sprintf("Information on dataset after variable gene determination of dataset %s\n", dataset_name))
cat(sprintf("Removed %d genes that apparently are not very variable \n\n", dim(data)[2] - length(top_genes) )) 

data = data[ , top_genes]
cat(sprintf("\nThere are %d cells and %d features.\n", dim(data)[1], dim(data)[2]))
for (i in 1:length(table(labels$ident))) {
  cat(sprintf("%-25s %d\n", names(table(labels$ident)[i]), table(labels$ident)[i]))
}
cat(sprintf("\n"))

if (SEURAT_VERBOSE) {
  
  # plot variable features with and without labels
  p1 <- VariableFeaturePlot(seurat_object)
  p2 <- LabelPoints(plot   = p1, 
                    points = top_genes[1:15], 
                    repel  = TRUE)
  grid.arrange(p1, p2, nrow = 1)
  rm(p1, p2)
  
  cluster_resolution = 0.5
  
  seurat_object <- run_seurat_analysis(seurat_object)
      
  FeatureScatter(seurat_object, feature1 = "nCount_RNA", feature2 = "nFeature_RNA") + NoLegend()
  VlnPlot(seurat_object, features = c("nFeature_RNA", "nCount_RNA"), ncol = 2)
  DimPlot(seurat_object, reduction = 'pca')
  DimPlot(seurat_object, reduction = 'tsne')
  DimPlot(seurat_object, reduction = 'umap', label = TRUE) + NoLegend()
  VizDimLoadings(seurat_object, dims = 1:4, reduction = 'pca')
  DimHeatmap(seurat_object, dims = 1:15, cells = 500, balanced = TRUE)
  ElbowPlot(seurat_object)
}

```


# Caret processing
Here starts the actual training and prediction processing 


```{r}

save_data   <- data
save_labels <- labels

```


### GBM NORMAL

```{r, gbm, , fig.width = 5}
model_gbm        <- NULL
gbm_accuracy     <- 0
log_preprocess   <- FALSE
caret_preprocess_method <- c('scale', 'center', 'pca')
  
if (TRAIN_GBM_PP_PCA) {
  
  data   <- save_data
  labels <- save_labels
  
  # Limit the data set to the number of genes specified in 'features_limit' 
  ldata = as.data.frame(data[ , top_genes[1:features_limit]])
  
  ldata           <- cbind.data.frame(labels, ldata)
  ldata           <- ldata %>% select(-one_of("cell_id"))
  trainRowNumbers <- createDataPartition(ldata$ident, p = 0.8, list = FALSE)
  
  train_data      <- ldata[trainRowNumbers,]
  test_data       <- ldata[-trainRowNumbers,]
  

  preproc_model   <- preProcess(train_data, 
                                method  = caret_preprocess_method,
                                thresh  = PCA_Threshold,
                                verbose = TRUE)
 
  pp_train_data   <- predict(preproc_model, train_data)

  model_gbm       <- train(ident ~ ., 
                           data      = pp_train_data, 
                           method    = "gbm",
                           trControl = trainControl("cv", 
                                                    number = 5, 
                                                    classProbs = TRUE,
                                                    verboseIter = TRUE)) 
  

  ###########################################################################
  # Predict and Evaluate
  ###########################################################################

  ret         <- predict_model_with_labels(method       = "gbm",
                                           model        = model_gbm, 
                                           model_name   = dataset_name,
                                           dataset_name = dataset_name,
                                           data         = test_data, 
                                           labels       = test_data[,1:2], 
                                           report_out   = report_out)
  
  report_out        <- ret$report_out
  predicted_classes <- ret$predicted_classes
  class_summary     <- ret$class_summary
  
  # cat(sprintf("Percentage correct after setting a threshold of %2.1f moves from %2.1f%% to %2.1f%% (%2.f%% unassigned)\n", 
  #             min_prob_value,
  #             correct_predicted_percentage,
  #             correct_assigned_percentage,
  #             unassigned_percentage))
  
  cm <- confusionMatrix(test_data[,1],
                        predicted_classes,
                        mode = "everything",
                        dnn = c("Reference", "Predicted"))
  print(cm)
  gbm_accuracy <- cm[["overall"]][["Accuracy"]]
  gbm_F1       <- median(cm[["byClass"]][,"F1"], na.rm = TRUE)

  print(class_summary)
}
```



### GBM NO PCA

```{r, gbm, , fig.width = 5}
model_gbm        <- NULL
gbm_accuracy     <- 0
log_preprocess   <- FALSE
caret_preprocess_method <- c('scale', 'center')
  
if (TRAIN_GBM_PP_NO_PCA) {
  
  data   <- save_data
  labels <- save_labels
  
  # Limit the data set to the number of genes specified in 'features_limit' (1000 has been found to be a good choice)
  ldata              <- as.data.frame(data[ , top_genes[1:features_limit]])
  
  ldata              <- cbind.data.frame(labels, ldata)
  ldata              <- ldata %>% select(-one_of("cell_id"))
  trainRowNumbers    <- createDataPartition(ldata$ident, p = 0.8, list = FALSE)
  
  train_data         <- ldata[trainRowNumbers,]
  test_data          <- ldata[-trainRowNumbers,]
 
  preproc_model      <- preProcess(train_data, 
                                   method  = caret_preprocess_method,
                                   thresh  = PCA_Threshold,
                                   verbose = TRUE)
  
  pp_train_data      <- predict(preproc_model, train_data)
      
  model_gbm          <- train(ident ~ ., 
                              data      = pp_train_data, 
                              method    = "gbm",
                              trControl = trainControl("cv", 
                                                       number = 5, 
                                                       classProbs = TRUE,
                                                       verboseIter = TRUE)) 
          

  ###########################################################################
  # Predict and Evaluate
  ###########################################################################

  ret               <- predict_model_with_labels(method       = "gbm",
                                                 model        = model_gbm, 
                                                 model_name   = dataset_name,
                                                 dataset_name = dataset_name,
                                                 data         = test_data, 
                                                 labels       = test_data[,1:2], 
                                                 report_out   = report_out)
  
  report_out        <- ret$report_out
  predicted_classes <- ret$predicted_classes
  class_summary     <- ret$class_summary
  
  # cat(sprintf("Percentage correct after setting a threshold of %2.1f moves from %2.1f%% to %2.1f%% (%2.f%% unassigned)\n", 
  #             min_prob_value,
  #             correct_predicted_percentage,
  #             correct_assigned_percentage,
  #             unassigned_percentage))
  
  cm <- confusionMatrix(test_data[,1],
                        predicted_classes,
                        mode = "everything",
                        dnn = c("Reference", "Predicted"))
  print(cm)
  gbm_accuracy <- cm[["overall"]][["Accuracy"]]
  gbm_F1       <- median(cm[["byClass"]][,"F1"], na.rm = TRUE)
  
  print(class_summary) 
}
```




### GBM LOG

```{r, gbm, , fig.width = 5}
model_gbm        <- NULL
gbm_accuracy     <- 0
log_preprocess   <- TRUE
caret_preprocess_method <- c('scale', 'center', 'pca')
  
if (TRAIN_GBM_PP_LOG) {
  
  data   <- save_data
  labels <- save_labels
  method <- "gbm"
  
  if (log_preprocess == TRUE) {
    data   <- log(1 + data)
  }
  
  # Limit the data set to the number of genes specified in 'features_limit' (1000 has been found to be a good choice)
  ldata = as.data.frame(data[ , top_genes[1:features_limit]])
  
  ldata              <- cbind.data.frame(labels, ldata)
  ldata              <- ldata %>% select(-one_of("cell_id"))
  trainRowNumbers    <- createDataPartition(ldata$ident, p = 0.8, list = FALSE)
  
  train_data         <- ldata[trainRowNumbers,]
  test_data          <- ldata[-trainRowNumbers,]
  
  preproc_model      <- preProcess(train_data, 
                                   method  = caret_preprocess_method,
                                   thresh  = PCA_Threshold,
                                   verbose = TRUE)
  
  pp_train_data      <- predict(preproc_model, train_data)

  model_gbm          <- train(ident ~ ., 
                              data      = pp_train_data, 
                              method    = method,
                              trControl = trainControl("cv", 
                                                       number = 5, 
                                                       classProbs = TRUE,
                                                       verboseIter = TRUE)) 
  

  ###########################################################################
  # Predict and Evaluate
  ###########################################################################
  
  ret         <- predict_model_with_labels(method       = "gbm",
                                           model        = model_gbm, 
                                           model_name   = dataset_name,
                                           dataset_name = dataset_name,
                                           data         = test_data, 
                                           labels       = test_data[,1:2], 
                                           report_out   = report_out)
  
  report_out        <- ret$report_out 
  predicted_classes <- ret$predicted_classes
  class_summary     <- ret$class_summary
  
  # cat(sprintf("Percentage correct after setting a threshold of %2.1f moves from %2.1f%% to %2.1f%% (%2.f%% unassigned)\n", 
  #             min_prob_value,
  #             correct_predicted_percentage,
  #             correct_assigned_percentage,
  #             unassigned_percentage))
  
  cm <- confusionMatrix(test_data[,1],
                        predicted_classes,
                        mode = "everything",
                        dnn = c("Reference", "Predicted"))
  print(cm)
  gbm_accuracy <- cm[["overall"]][["Accuracy"]]
  gbm_F1       <- median(cm[["byClass"]][,"F1"], na.rm = TRUE)
  
  print(class_summary)
}
```
