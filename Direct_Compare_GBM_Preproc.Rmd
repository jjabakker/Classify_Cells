---
title: "Debug SVM"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include = FALSE} 
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
rm(list = ls())
set.seed(1234)
```


# Specify key use parameters

Model and datset options are:

Baron_Mouse  # 1,886 cells, 14,861 genes
Baron_Human  # 8,569 cells, 17,499 genes
Muraro       # 2,122 cells, 18,915 genes
SegerStolpe  # 2,133 cells, 22,757 genes
Xin          # 1,449 cells, 33,889 genes
Zhou         # 2,554 cells, 19,046 genes
Bo           # 516   cells, 56,924 genes
Petropoulos1 # 1,529 cells, 26,178 genes 


```{r}

# Select dataset 

dataset_name         <- "Bo"

# Specify which models should be run
# Note that it possible that a model is not available in the modelset, in which case the instruction is simply ignored

TRAIN_GBM_PP_PCA     <- TRUE
TRAIN_GBM_PP_NO_PCA  <- TRUE
TRAIN_GBM_PP_LOG     <- TRUE

```


# Initialise

```{r, libraries, message=FALSE}

library(readr)
library(tibble)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(Seurat)
library(caret)
library(data.table)
library(matrixStats)
library(tictoc)
library(MazamaCoreUtils)        # Used for logging messages to a file

source("Code/Train/process_config.R")
source("Code/Train/read_dataset.R")
source("Code/Predict/predict_model_with_labels.R")

```


```{r, initialise, message=FALSE}

PCA_Threshold    <- 0.90         # The percentage variance explained by the PCA
                                 # A high percentage requires more PC dimensions to be considered

features_limit   <- 1000         # The number of features that will be considered duringthe PCA
                                 # A high number uses the richness of the data set optimally, but makes processing slo

VERBOSE          <- TRUE         # If TRUE generates analysis data
LOGGER           <- FALSE

# Summary results will be kept here 
report_out       <- data.frame()

# Information of all the runs will be gathered in the class_summaries list  
class_summaries  <- list()

```


```{r, path and timer}

proj_path   <- file.path(".")
data_path   <- file.path(proj_path, "DataSets")
log_path    <- file.path(proj_path, "Logs")
rdata_path  <- file.path(proj_path, "rData")
config_path <- file.path(proj_path, "config")

logger.setup (infoLog = file.path(log_path, paste0("pp_compare.log")))

```

# Read in the data


```{r, Read and config}

ret                 <- read_dataset(data_path, dataset_name)
data                <- ret$data
labels              <- ret$labels

config_data         <- read_config(config_path  = config_path,
                                   dataset_name = dataset_name)
  
min_class_size      <- config_data["min_class_size", "Value"]
cluster_resolution  <- config_data["cluster_resolution", "Value"] 
minCount            <- config_data["minCount", "Value"] 
maxCount            <- config_data["maxCount", "Value"]
minFeature          <- config_data["minFeature", "Value"] 
maxFeature          <- config_data["maxFeature", "Value"] 

########################################
# Overrule settings from config file
########################################

min_class_size      <- 10 
minCount            <- 0 
maxCount            <- -1
minFeature          <- 0 
maxFeature          <- -1 

ret                 <- process_config(min_class_size, minCount, maxCount, minFeature, maxFeature, data, labels)
data                <- ret$data
labels              <- ret$labels

```

```{r}

save_data   <- ret$data
save_labels <- ret$labels

```



# Find the Variable Genes 

```{r, variable_features, fig.height=5, message = FALSE, echo=FALSE}


seurat_object <- CreateSeuratObject(counts    = t(data),
                                    meta.data = as.data.frame(labels),
                                    min.cells = 5)

seurat_object <- NormalizeData(seurat_object, 
                               normalization.method = "LogNormalize", 
                               scale.factor = 1000000)

seurat_object <- FindVariableFeatures(object           = seurat_object, 
                                      selection.method = 'vst',
                                      verbose          = TRUE,
                                      nfeatures        = dim(data)[2])

# Identify the most highly variable genes
top_genes     <- VariableFeatures(seurat_object)

# Show composition
cat(sprintf("Information on dataset after variable gene determination of dataset %s\n", dataset_name))
cat(sprintf("Removed %d genes that apparently are not very variable \n\n", dim(data)[2] - length(top_genes) )) 

data = data[ , top_genes]
cat(sprintf("\nThere are %d cells and %d features.\n", dim(data)[1], dim(data)[2]))
for (i in 1:length(table(labels$ident))) {
  cat(sprintf("%-25s %d\n", names(table(labels$ident)[i]), table(labels$ident)[i]))
}
cat(sprintf("\n"))

```


# Caret processing
Here starts the actual training and prediction processing 



### GBM NORMAL

```{r, gbm, , fig.width = 5}
model_gbm               <- NULL
gbm_accuracy            <- 0
log_preprocess          <- FALSE
caret_preprocess_method <- c('scale', 'center', 'pca')
  
if (TRAIN_GBM_PP_PCA) {
  
  data   <- save_data
  labels <- save_labels
  
  if (log_preprocess) {
    data <- log(1 + data)
  }
  
  # Limit the data set to the number of genes specified in 'features_limit' 
  ldata = as.data.frame(data[ , top_genes[1:features_limit]])
  
  ldata           <- cbind.data.frame(labels, ldata)
  ldata           <- ldata %>% select(-one_of("cell_id"))
  trainRowNumbers <- createDataPartition(ldata$ident, p = 0.8, list = FALSE)
  
  train_data      <- ldata[trainRowNumbers,]
  test_data       <- ldata[-trainRowNumbers,]
  

  preproc_model   <- preProcess(train_data, 
                                method  = caret_preprocess_method,
                                thresh  = PCA_Threshold,
                                verbose = TRUE)
 
  pp_train_data   <- predict(preproc_model, train_data)

  model_gbm       <- train(ident ~ ., 
                           data      = pp_train_data, 
                           method    = "gbm",
                           trControl = trainControl("cv", 
                                                    number = 5, 
                                                    classProbs = TRUE,
                                                    verboseIter = TRUE)) 
  

  ###########################################################################
  # Predict and Evaluate
  ###########################################################################

  ret               <- predict_model_with_labels(method         = "gbm",
                                                 preproc_method = preproc_method,
                                                 model          = model_gbm, 
                                                 preproc_model  = preproc_model,
                                                 model_name     = dataset_name,
                                                 dataset_name   = dataset_name,
                                                 data           = test_data, 
                                                 labels         = test_data[,1:2], 
                                                 report_out     = report_out)
  
  report_out        <- ret$report_out
  predicted_classes <- ret$predicted_classes
  class_summary     <- ret$class_summary
  
  cm <- confusionMatrix(test_data[,1],
                        predicted_classes,
                        mode = "everything",
                        dnn = c("Reference", "Predicted"))
  print(cm)
  pca_accuracy      <- cm[["overall"]][["Accuracy"]]
  pca_F1            <- median(cm[["byClass"]][,"F1"], na.rm = TRUE)

  print(class_summary)
}
```



### GBM NO PCA

```{r, gbm, , fig.width = 5}
model_gbm               <- NULL
gbm_accuracy            <- 0
log_preprocess          <- FALSE
caret_preprocess_method <- c('scale', 'center')
  
if (TRAIN_GBM_PP_NO_PCA) {
  
  data                  <- save_data
  labels                <- save_labels
  
  if (log_preprocess) {
    data                <- log(1 + data)
  }
  
  # Limit the data set to the number of genes specified in 'features_limit' (1000 has been found to be a good choice)
  ldata                 <- as.data.frame(data[ , top_genes[1:features_limit]])
  
  ldata                 <- cbind.data.frame(labels, ldata)
  ldata                 <- ldata %>% select(-one_of("cell_id"))
  trainRowNumbers       <- createDataPartition(ldata$ident, p = 0.8, list = FALSE)
  
  train_data            <- ldata[trainRowNumbers,]
  test_data             <- ldata[-trainRowNumbers,]
 
  preproc_model         <- preProcess(train_data, 
                                      method  = caret_preprocess_method,
                                      thresh  = PCA_Threshold,
                                      verbose = TRUE)
  
  pp_train_data         <- predict(preproc_model, train_data)
      
  model_gbm             <- train(ident ~ ., 
                                 data      = pp_train_data, 
                                 method    = "gbm",
                                 trControl = trainControl("cv", 
                                                          number = 5, 
                                                          classProbs = TRUE,
                                                          verboseIter = TRUE)) 
          

  ###########################################################################
  # Predict and Evaluate
  ###########################################################################

  ret                 <- predict_model_with_labels(method         = "gbm",
                                                   preproc_method = preproc_method,
                                                   model          = model_gbm,
                                                   preproc_model  = preproc_model,
                                                   model_name     = dataset_name,
                                                   dataset_name   = dataset_name,
                                                   data           = test_data, 
                                                   labels         = test_data[,1:2], 
                                                   report_out     = report_out)
  
  report_out          <- ret$report_out
  predicted_classes   <- ret$predicted_classes
  class_summary       <- ret$class_summary
  
  cm <- confusionMatrix(test_data[,1],
                        predicted_classes,
                        mode = "everything",
                        dnn = c("Reference", "Predicted"))
  print(cm)
  no_pca_accuracy     <- cm[["overall"]][["Accuracy"]]
  no_pca_F1           <- median(cm[["byClass"]][,"F1"], na.rm = TRUE)
  
  print(class_summary) 
}
```




### GBM LOG

```{r, gbm, , fig.width = 5}

model_gbm               <- NULL
gbm_accuracy            <- 0
log_preprocess          <- TRUE
caret_preprocess_method <- c('scale', 'center', 'pca')
  
if (TRAIN_GBM_PP_LOG) {
  
  data   <- save_data
  labels <- save_labels
  method <- "gbm"
  
  if (log_preprocess == TRUE) {
    data   <- log(1 + data)
  }
  
  # Limit the data set to the number of genes specified in 'features_limit' (1000 has been found to be a good choice)
  ldata = as.data.frame(data[ , top_genes[1:features_limit]])
  
  ldata              <- cbind.data.frame(labels, ldata)
  ldata              <- ldata %>% select(-one_of("cell_id"))
  trainRowNumbers    <- createDataPartition(ldata$ident, p = 0.8, list = FALSE)
  
  train_data         <- ldata[trainRowNumbers,]
  test_data          <- ldata[-trainRowNumbers,]
  
  preproc_model      <- preProcess(train_data, 
                                   method  = caret_preprocess_method,
                                   thresh  = PCA_Threshold,
                                   verbose = TRUE)
  
  pp_train_data      <- predict(preproc_model, train_data)

  model_gbm          <- train(ident ~ ., 
                              data      = pp_train_data, 
                              method    = method,
                              trControl = trainControl("cv", 
                                                       number = 5, 
                                                       classProbs = TRUE,
                                                       verboseIter = TRUE)) 
  

  ###########################################################################
  # Predict and Evaluate
  ###########################################################################
  
  ret               <- predict_model_with_labels(method         = "gbm",
                                                 preproc_method = preproc_method,
                                                 model          = model_gbm,
                                                 preproc_model  = preproc_model,
                                                 model_name     = dataset_name,
                                                 dataset_name   = dataset_name,
                                                 data           = test_data, 
                                                 labels         = test_data[,1:2], 
                                                 report_out     = report_out)
  
  report_out        <- ret$report_out 
  predicted_classes <- ret$predicted_classes
  class_summary     <- ret$class_summary
  
  cm <- confusionMatrix(test_data[,1],
                        predicted_classes,
                        mode = "everything",
                        dnn = c("Reference", "Predicted"))
  print(cm)
  log_accuracy      <- cm[["overall"]][["Accuracy"]]
  log_F1            <- median(cm[["byClass"]][,"F1"], na.rm = TRUE)
  
  print(class_summary)
}

```
